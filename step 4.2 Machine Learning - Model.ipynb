{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384a70a6",
   "metadata": {},
   "source": [
    "# step 4.2 Machine Learning - Model\n",
    "creating a model and optimizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140a5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn import tree,metrics\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d922af",
   "metadata": {},
   "source": [
    "## spliting to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e140baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"finale_normalized_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c828eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_train_and_test(dataset, label_column, test_ratio, rand_state):\n",
    "    TRAINING_FEATURES = dataset.columns[dataset.columns != label_column]\n",
    "    TARGET_FEATURE = label_column\n",
    "    X=dataset[TRAINING_FEATURES]\n",
    "    y= dataset[TARGET_FEATURE]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rand_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "144311ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9159, 48) (2290, 48) (9159,) (2290,)\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = dataset\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4df53",
   "metadata": {},
   "source": [
    "## first Model \n",
    "ניסיון ראשון ביצירת מודל, שימוש בשלושה סוגים עם היפרפרמטרים ברירת מחדל ללא אופטימיזציה."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0b9e36e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "======\n",
      "accuracy on train data 0.9585107544491757\n",
      "accuracy on test data 0.7489082969432315\n",
      "[[1585   25   14   34   47   59]\n",
      " [  14    2    0    3    3    4]\n",
      " [  16    2    0    3    4    5]\n",
      " [  33    4    2   21   33   11]\n",
      " [  60    3    5   20   85   28]\n",
      " [  71    3    5   19   45   22]]\n",
      "RandForest\n",
      "======\n",
      "accuracy on train data 0.9585107544491757\n",
      "accuracy on test data 0.7794759825327511\n",
      "[[1658    5    7   13   51   30]\n",
      " [  16    0    0    2    5    3]\n",
      " [  16    1    1    3    6    3]\n",
      " [  32    2    0   19   39   12]\n",
      " [  67    5    2   16   86   25]\n",
      " [  76    2    2   15   49   21]]\n",
      "KNN\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train data 0.8495468937656949\n",
      "accuracy on test data 0.7816593886462883\n",
      "[[1695   10    4   10   27   18]\n",
      " [  15    1    1    5    2    2]\n",
      " [  22    1    0    3    3    1]\n",
      " [  45    3    3   12   29   12]\n",
      " [  79    1    5   27   69   20]\n",
      " [  91    4    6   15   36   13]]\n"
     ]
    }
   ],
   "source": [
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "algs = [\"DT\",\"RandForest\",\"KNN\"]\n",
    "clfs = [clf1,clf2,clf3]\n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(algs[i])\n",
    "    print(\"======\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "    print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d78cd",
   "metadata": {},
   "source": [
    "הגענו לרמת דיוק של כ-0.78 בק\"ננ ועם רמת דיוק על סט המבחן של כ 0.84.\n",
    "בנוסף ביער ובעץ ההחלטה רואים שיש אוברפיטינג ואחוז דיוק נמוך בהרבה בהשווה לזה של סט הבדיקה\n",
    "נרצה לנסות וליעל את המודלים."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1baf210",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "ננסה למצוא את הפרמטרים הטובים ביותר למודלים במטרה ליעל אותם"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc4268b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"finale_normalized_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6a04227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9159, 48) (2290, 48) (9159,) (2290,)\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = tr_df\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7a2f6",
   "metadata": {},
   "source": [
    "ניסינו לבדוק סוגי מודלים נוספים:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad5331bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "======\n",
      "accuracy on train data 0.9585107544491757\n",
      "accuracy on test data 0.751528384279476\n",
      "[[1590   21   12   29   51   61]\n",
      " [  15    1    0    3    3    4]\n",
      " [  14    3    0    4    3    6]\n",
      " [  33    4    2   23   32   10]\n",
      " [  60    3    4   23   85   26]\n",
      " [  67    3    3   24   46   22]]\n",
      "RandForest\n",
      "======\n",
      "accuracy on train data 0.9582923899989082\n",
      "accuracy on test data 0.780349344978166\n",
      "[[1661    6    4   15   50   28]\n",
      " [  15    0    0    4    5    2]\n",
      " [  16    1    1    2    7    3]\n",
      " [  33    3    0   17   40   11]\n",
      " [  62    4    2   17   88   28]\n",
      " [  73    1    2   17   52   20]]\n",
      "KNN\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train data 0.8356807511737089\n",
      "accuracy on test data 0.7851528384279476\n",
      "[[1688    2    3   13   39   19]\n",
      " [  17    0    0    4    3    2]\n",
      " [  22    0    0    1    5    2]\n",
      " [  44    0    1   14   38    7]\n",
      " [  79    2    2   22   80   16]\n",
      " [  86    0    0   17   46   16]]\n",
      "NaiveByse\n",
      "======\n",
      "accuracy on train data 0.3035265858718201\n",
      "accuracy on test data 0.3056768558951965\n",
      "[[ 666    1 1090    7    0    0]\n",
      " [   2    0   24    0    0    0]\n",
      " [   3    0   24    3    0    0]\n",
      " [   3    3   94    2    2    0]\n",
      " [   6    0  171   15    8    1]\n",
      " [   8    0  152    5    0    0]]\n",
      "SVC\n",
      "======\n",
      "accuracy on train data 0.8041270881100557\n",
      "accuracy on test data 0.8026200873362446\n",
      "[[1730    0    0    0   34    0]\n",
      " [  19    0    0    0    7    0]\n",
      " [  24    0    0    0    6    0]\n",
      " [  56    0    0    0   48    0]\n",
      " [  93    0    0    0  108    0]\n",
      " [  97    0    0    0   68    0]]\n"
     ]
    }
   ],
   "source": [
    "clf1 = tree.DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier(random_state=5)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf4 = GaussianNB()\n",
    "clf5 = SVC()\n",
    "\n",
    "algs = [\"DT\",\"RandForest\",\"KNN\",\"NaiveByse\",\"SVC\"]\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5]\n",
    "for i,clf in enumerate(clfs):\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(algs[i])\n",
    "    print(\"======\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "    print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "    print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "    \n",
    "    print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa9962",
   "metadata": {},
   "source": [
    "ניתן לראות כי:\n",
    "\n",
    "    1. DT: ניתן לראות רמת דיוק של כ-0.95 על סט הטסט אך רק 0.75 על המבחן, הדבר מראה על אוברפיטינג של המודל, ננסה לסדר את הפרמטרים שלו במטרה לקבל מודל תקין.\n",
    "    \n",
    "    2.RandForest: ניתן לראות רמת דיוק של כ-0.95 על סט הטסט אך רק 0.78 על המבחן, הדבר מראה על אוברפיטינג של המודל, ננסה לסדר את הפרמטרים שלו במטרה לקבל מודל תקין.\n",
    "        \n",
    "    3.KNN: כ-0.78 על סט המבחןת ננסה לעלות את רמת הדיוק על ידי מציאת הפרמטר הטוב ביותר\n",
    "        \n",
    "    4.NaiveByse: רמת דיוק של כ-0.3 גם בסט המבחן וגם בסט הטסט, מודל זה אינו מתאים לנו\n",
    "        \n",
    "    5.SVC: רמת דיוק של כ 0.80 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06f213",
   "metadata": {},
   "source": [
    "ניסינו לשפר את מודל הקנ\"נ ואכן הצלחנו למצוא פרמטרים ששיפרו את רמת הדיוק שלו לכ- 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb16b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_for_KNN(X_train, y_train):\n",
    "    parameters= {'n_neighbors': [3,5,7,9,11,15,21,23,19,25,27,29]}\n",
    "    knn= KNeighborsClassifier()\n",
    "    clf= GridSearchCV(knn,parameters, scoring=make_scorer(metrics.accuracy_score, greater_is_better=True))\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_K= clf.best_params_['n_neighbors']\n",
    "    best_f1_val= clf.best_score_\n",
    "    return best_K, best_f1_val\n",
    "\n",
    "best_K, best_accuracy_score=find_best_k_for_KNN(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4614bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8037991385622194\n",
      "bestk 29\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", best_accuracy_score)\n",
    "print(\"bestk\", best_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e2d63",
   "metadata": {},
   "source": [
    "נתמקד בניסיון לשפר את מודל היער על ידי שינוי פרמטרים:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "045ec051",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param ={ \n",
    "    \"n_estimators\":[90,100,115,130],\n",
    "    \"max_depth\":range(10,20,1),\n",
    "    \"min_samples_split\":range(10,20,1),\n",
    "    \"random_state\": range(1,5,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4886f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=clf2 , param_grid = grid_param, cv=5, n_jobs=-1, verbose=3,scoring=make_scorer(metrics.accuracy_score, greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c81eb395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1600 candidates, totalling 8000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': range(10, 20),\n",
       "                         'min_samples_split': range(10, 20),\n",
       "                         'n_estimators': [90, 100, 115, 130],\n",
       "                         'random_state': range(1, 5)},\n",
       "             scoring=make_scorer(accuracy_score), verbose=3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7ebd6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 130,\n",
       " 'random_state': 2}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "833bd41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandForest\n",
      "======\n",
      "accuracy on train data 0.8401572224041925\n",
      "accuracy on test data 0.8109170305676856\n",
      "[[1731    0    0    0   28    5]\n",
      " [  17    0    0    0    8    1]\n",
      " [  21    0    0    1    6    2]\n",
      " [  49    0    0    2   49    4]\n",
      " [  79    0    0    2  109   11]\n",
      " [  93    0    0    2   55   15]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=130, max_depth=15,min_samples_split=15, random_state=2)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"RandForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "    \n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d7cc7",
   "metadata": {},
   "source": [
    "ראינו שיפור ברמת דיור המודל על סט המבחן וירידה בדיוק על סט הבדיקהת מכך ניתן ללמוד כי אנו לא נמצאים במצב של אוברפיטינג יותר.\n",
    "רמת דיוק על סט המבחן הינה 0.81."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da436b86",
   "metadata": {},
   "source": [
    "ננסה לשפר גם את מודל העץ החלטה:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f637da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param ={\n",
    "    \"min_samples_leaf\" : range(1,15,1),\n",
    "    \"max_depth\":[5,10,15,30],\n",
    "    \"min_samples_split\":range(1,15,1),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf1 , param_grid = grid_param, cv=5, n_jobs=-1, verbose=3, scoring=make_scorer(metrics.accuracy_score, greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01e7bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b42c209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_leaf': 14, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d619083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandForest\n",
      "======\n",
      "accuracy on train data 0.8131892127961567\n",
      "accuracy on test data 0.8013100436681223\n",
      "[[1722    0    0    1   41    0]\n",
      " [  16    0    0    0   10    0]\n",
      " [  21    0    0    0    9    0]\n",
      " [  43    0    0    1   60    0]\n",
      " [  87    0    0    2  112    0]\n",
      " [ 103    0    0    0   62    0]]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5,min_samples_split=2,min_samples_leaf= 14 )\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"RandForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "    \n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ead70e",
   "metadata": {},
   "source": [
    "נעבור לשיפוא מודל האסויסי:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cac9697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.771 total time=   6.2s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.770 total time=   6.8s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.771 total time=   6.6s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.772 total time=   6.8s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.771 total time=   5.7s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.805 total time=   2.8s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.797 total time=   3.1s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.803 total time=   3.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.810 total time=   2.9s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.805 total time=   3.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.805 total time=   3.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.798 total time=   2.9s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.801 total time=   2.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.808 total time=   2.5s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.804 total time=   2.8s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.766 total time=   2.6s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.766 total time=   2.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.766 total time=   2.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.766 total time=   2.3s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.766 total time=   2.2s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.2s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.4s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.2s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.797 total time=   7.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.792 total time=   7.4s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.794 total time=   7.6s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.801 total time=   7.2s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.792 total time=   6.7s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.806 total time=   3.1s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.801 total time=   3.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.801 total time=   2.9s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.809 total time=   3.1s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.803 total time=   3.3s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.803 total time=   3.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.801 total time=   3.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.800 total time=   2.9s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.809 total time=   2.9s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.803 total time=   2.9s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.805 total time=   2.6s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.800 total time=   3.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.800 total time=   2.5s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.811 total time=   2.7s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.803 total time=   2.6s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.4s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.4s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.6s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   2.8s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.766 total time=   3.1s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.784 total time=   8.2s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.785 total time=   7.4s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.788 total time=   7.9s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.788 total time=   8.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.787 total time=   6.9s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.801 total time=   3.6s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.801 total time=   4.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.802 total time=   3.8s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.800 total time=   2.9s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.793 total time=   3.7s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.807 total time=   3.9s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.803 total time=   4.1s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.802 total time=   4.5s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.809 total time=   3.8s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.804 total time=   4.5s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.805 total time=   3.1s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.802 total time=   3.3s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.800 total time=   3.3s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.809 total time=   3.3s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.803 total time=   3.2s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.803 total time=   3.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.801 total time=   3.2s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.800 total time=   2.8s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.810 total time=   3.4s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.802 total time=   2.7s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.783 total time=   7.7s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.783 total time=   8.1s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.788 total time=   7.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.787 total time=   8.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.786 total time=   7.6s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.776 total time=   3.9s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.776 total time=   4.2s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.782 total time=   4.5s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.780 total time=   4.7s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.782 total time=   4.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.807 total time=   4.8s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.797 total time=   4.9s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.803 total time=   5.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.807 total time=   5.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.806 total time=   5.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.806 total time=   6.1s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.802 total time=   6.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.803 total time=   6.6s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.808 total time=   6.5s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.805 total time=   6.8s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.805 total time=   3.9s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.802 total time=   3.3s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.800 total time=   3.4s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.809 total time=   3.5s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.803 total time=   3.5s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.782 total time=   7.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.777 total time=   7.8s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.788 total time=   7.6s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.784 total time=   8.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.781 total time=   8.1s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.779 total time=   4.7s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.773 total time=   4.9s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.782 total time=   4.8s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.774 total time=   5.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.780 total time=   4.3s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.799 total time=   9.1s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.794 total time=   8.7s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.806 total time=   9.2s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.801 total time=   9.2s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.798 total time=   9.6s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.806 total time=  11.3s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.803 total time=  13.4s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.801 total time=  13.2s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.809 total time=  12.4s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.804 total time=  13.4s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.806 total time=   8.3s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.802 total time=   8.6s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.803 total time=   8.8s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.808 total time=   9.1s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.805 total time=   9.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e6852b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf4343d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "======\n",
      "accuracy on train data 0.8059831859373294\n",
      "accuracy on test data 0.8030567685589519\n",
      "[[1726    0    0    0   37    1]\n",
      " [  18    0    0    0    8    0]\n",
      " [  23    0    0    0    7    0]\n",
      " [  56    0    0    0   48    0]\n",
      " [  88    0    0    0  113    0]\n",
      " [  94    0    0    0   71    0]]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C= 10, gamma=0.01 ,kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"SVC\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "    \n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "    \n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88c7d3",
   "metadata": {},
   "source": [
    "לא נראה שיפור משמעותי (0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d189d2",
   "metadata": {},
   "source": [
    "The F1 score is a popular performance measure for classification and often preferred over, for example,\n",
    "accuracy when data is unbalanced, such as when the quantity of examples belonging to one class \n",
    "significantly outnumbers those found in the other class.\n",
    "\n",
    "https://c3.ai/glossary/data-science/f1-score/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd09f32",
   "metadata": {},
   "source": [
    "ניתן לראות שהדאטה שלנו אכן לא מאוזן עם כמות גדולה משמעותית של דוגמאות מדורגות 0 לכן נכון יותר לבדוק את:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a83f22d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score Score for test:  0.7630028669533551\n",
      "f1_score Score for train:  0.8050682580420803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=130, max_depth=15,min_samples_split=15, random_state=2)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"f1_score Score for test: \",f1_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='weighted'))\n",
    "\n",
    "print(\"f1_score Score for train: \",f1_score(y_train, y_pred_train, \n",
    "                                           pos_label='positive',\n",
    "                                           average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d41760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score Score for test:  0.7463151694098566\n",
      "f1_score Score for train:  0.7509333386190127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C= 10, gamma=0.01 ,kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"f1_score Score for test: \",f1_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='weighted'))\n",
    "\n",
    "print(\"f1_score Score for train: \",f1_score(y_train, y_pred_train, \n",
    "                                           pos_label='positive',\n",
    "                                           average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc265567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077cb7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "046c5a2d",
   "metadata": {},
   "source": [
    "## third Model\n",
    "ננסה ליעל את המודל על ידי מניפוליזציה של טבלת הנתונים- ננסה להוסיף עמודות היכולות להשפיע על רמת הדיוק וכן ננסה להוריד עמודות בעלות קורליזציה גבוהה אחת לשנייה"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f5fa6757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>norm_prices</td>\n",
       "      <td>0.129788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XXXXL</td>\n",
       "      <td>0.098224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brand</td>\n",
       "      <td>0.093321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>0.091304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>0.084242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XXL</td>\n",
       "      <td>0.081900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>elastane</td>\n",
       "      <td>0.055845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>polyester</td>\n",
       "      <td>0.051443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>0.038947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cotton</td>\n",
       "      <td>0.023339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Black</td>\n",
       "      <td>0.018453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>viscose</td>\n",
       "      <td>0.018242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lining</td>\n",
       "      <td>0.017427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5XL</td>\n",
       "      <td>0.016633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>stretch</td>\n",
       "      <td>0.013847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>other_colors</td>\n",
       "      <td>0.011873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lightweight</td>\n",
       "      <td>0.011433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>White</td>\n",
       "      <td>0.010407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nylon</td>\n",
       "      <td>0.009904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Blue</td>\n",
       "      <td>0.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Brown</td>\n",
       "      <td>0.009117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XS</td>\n",
       "      <td>0.008771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L</td>\n",
       "      <td>0.008091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grey</td>\n",
       "      <td>0.007789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Green</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>midweight</td>\n",
       "      <td>0.006776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pink</td>\n",
       "      <td>0.006030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>knit</td>\n",
       "      <td>0.005970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>nonstretch</td>\n",
       "      <td>0.005925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6XL</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Red</td>\n",
       "      <td>0.005096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Purple</td>\n",
       "      <td>0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jersey</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lace</td>\n",
       "      <td>0.003844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>faux</td>\n",
       "      <td>0.003636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>weave</td>\n",
       "      <td>0.003454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Orange</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mesh</td>\n",
       "      <td>0.002601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heavyweight</td>\n",
       "      <td>0.002420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P</td>\n",
       "      <td>0.002398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>activewear</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>poplin</td>\n",
       "      <td>0.001021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>One_size</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>satin</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XXS</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features   weights\n",
       "44   norm_prices  0.129788\n",
       "9          XXXXL  0.098224\n",
       "0          brand  0.093321\n",
       "6              M  0.091304\n",
       "4              S  0.084242\n",
       "8            XXL  0.081900\n",
       "45      elastane  0.055845\n",
       "38     polyester  0.051443\n",
       "1       category  0.038947\n",
       "26        cotton  0.023339\n",
       "14         Black  0.018453\n",
       "42       viscose  0.018242\n",
       "33        lining  0.017427\n",
       "11           5XL  0.016633\n",
       "41       stretch  0.013847\n",
       "24  other_colors  0.011873\n",
       "32   lightweight  0.011433\n",
       "16         White  0.010407\n",
       "37         nylon  0.009904\n",
       "13          Blue  0.009217\n",
       "17         Brown  0.009117\n",
       "3             XS  0.008771\n",
       "7              L  0.008091\n",
       "15          Grey  0.007789\n",
       "20         Green  0.007481\n",
       "35     midweight  0.006776\n",
       "19          Pink  0.006030\n",
       "30          knit  0.005970\n",
       "36    nonstretch  0.005925\n",
       "12           6XL  0.005633\n",
       "22           Red  0.005096\n",
       "21        Purple  0.004907\n",
       "29        jersey  0.004484\n",
       "31          lace  0.003844\n",
       "27          faux  0.003636\n",
       "43         weave  0.003454\n",
       "18        Orange  0.003398\n",
       "23        Yellow  0.003088\n",
       "34          mesh  0.002601\n",
       "28   heavyweight  0.002420\n",
       "5              P  0.002398\n",
       "25    activewear  0.001176\n",
       "39        poplin  0.001021\n",
       "10      One_size  0.000556\n",
       "40         satin  0.000550\n",
       "2            XXS  0.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fDF= pd.DataFrame({\"features\":clf.feature_names_in_, \"weights\": clf.feature_importances_ })\n",
    "fDF.sort_values(\"weights\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc923fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df=dataset.copy(deep=True)\n",
    "temp= dataset[\"satin\"]\n",
    "tr_df.drop([\"satin\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a6b6137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "======\n",
      "accuracy on train data 0.8395021290533901\n",
      "accuracy on test data 0.8069868995633188\n",
      "f1_score Score for test:  0.7597443434345118\n",
      "[[1730    0    0    0   28    6]\n",
      " [  17    0    0    0    8    1]\n",
      " [  20    0    0    0    7    3]\n",
      " [  49    0    0    2   49    4]\n",
      " [  81    0    0    3  105   12]\n",
      " [  95    0    0    4   55   11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linoy\\Downloads\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1370: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = tr_df\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"RandomForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "print(\"f1_score Score for test: \",f1_score(y_test, y_pred, \n",
    "                                           pos_label='positive',\n",
    "                                           average='weighted'))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c406cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df[\"satin\"]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356430bc",
   "metadata": {},
   "source": [
    "ניסינו להוריד את העמודות בעלי ההשפעה הנמוכה ביותר על המודל אך ראינו שבהורדתן אנחנו מורידים מיכולת הדיוק של המודל ולכן בחרנו שלא להוריד אותם."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46879806",
   "metadata": {},
   "source": [
    "תחילה, ניסינו להוסיף עמודות הסופרות את מספר המידות ומספר הצבעים הקיימים לאותו הפריט, ההיגיון מאוחרי זה הינו שככל שקיימות יותר אופציות מידה\\צבע קהל הקונים של אותו הפריט רחב יותר ועל כן גם מספר הלקוחות עם פוטנציל לדירוג הפריט."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83c20971",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size_options=[]\n",
    "for ind in dataset.index:\n",
    "    count=0\n",
    "    if dataset['XXS'][ind]==1: count=count+1\n",
    "    if dataset['XS'][ind]==1: count=count+1\n",
    "    if dataset['S'][ind]==1: count=count+1\n",
    "    if dataset['P'][ind]==1: count=count+1\n",
    "    if dataset['M'][ind]==1: count=count+1\n",
    "    if dataset['L'][ind]==1: count=count+1\n",
    "    if dataset['XL'][ind]==1: count=count+1\n",
    "    if dataset['XXL'][ind]==1: count=count+1\n",
    "    if dataset['XXXL'][ind]==1: count=count+1\n",
    "    if dataset['XXXL'][ind]==1: count=count+1\n",
    "    if dataset['6XL'][ind]==1: count=count+1\n",
    "    if dataset['5XL'][ind]==1: count=count+1\n",
    "    if dataset['One_size'][ind]==1: count=count+1\n",
    "        \n",
    "    total_size_options.append(count)\n",
    "    \n",
    "dataset[\"total_size_options\"]=total_size_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d822ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9159, 49) (2290, 49) (9159,) (2290,)\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = dataset\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "691be472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "======\n",
      "accuracy on train data 0.8432143247079376\n",
      "accuracy on test data 0.8034934497816594\n",
      "[[1722    0    0    0   38    4]\n",
      " [  17    0    0    0    7    2]\n",
      " [  20    0    0    1    5    4]\n",
      " [  48    0    0    3   47    6]\n",
      " [  80    0    0    3  102   16]\n",
      " [  96    0    0    3   53   13]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "print(\"RandomForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d2d47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"total_size_options\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1fcdd",
   "metadata": {},
   "source": [
    "ניתן לראות ירידה בדיוק המודל לכן החלטנו להוריד את העמודה הזו."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cd4e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_color_options=[]\n",
    "for ind in dataset.index:\n",
    "    count=0\n",
    "    if dataset['Blue'][ind]==1: count=count+1\n",
    "    if dataset['Black'][ind]==1: count=count+1\n",
    "    if dataset['Grey'][ind]==1: count=count+1\n",
    "    if dataset['White'][ind]==1: count=count+1\n",
    "    if dataset['Brown'][ind]==1: count=count+1\n",
    "    if dataset['Orange'][ind]==1: count=count+1\n",
    "    if dataset['Pink'][ind]==1: count=count+1\n",
    "    if dataset['Green'][ind]==1: count=count+1\n",
    "    if dataset['Purple'][ind]==1: count=count+1\n",
    "    if dataset['Red'][ind]==1: count=count+1\n",
    "    if dataset['Yellow'][ind]==1: count=count+1\n",
    "    if dataset['other_colors'][ind]==1: count=count+1\n",
    "    if dataset['One_size'][ind]==1: count=count+1\n",
    "        \n",
    "    total_color_options.append(count)\n",
    "\n",
    "dataset[\"total_color_options\"]=total_color_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "75262731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9159, 49) (2290, 49) (9159,) (2290,)\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = dataset\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bf146b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "======\n",
      "accuracy on train data 0.8424500491320013\n",
      "accuracy on test data 0.8065502183406114\n",
      "[[1724    0    0    0   32    8]\n",
      " [  18    0    0    0    7    1]\n",
      " [  21    0    0    1    7    1]\n",
      " [  50    0    0    2   46    6]\n",
      " [  82    0    0    3  108    8]\n",
      " [  94    0    0    3   55   13]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "print(\"RandomForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3866654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"total_color_options\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8476534",
   "metadata": {},
   "source": [
    "ניתן לראות ירידה בדיוק המודל לכן החלטנו להוריד את העמודה הזו."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8d5e7",
   "metadata": {},
   "source": [
    "ראינו קורלציה גבוהה בין עמודות ה: (אלסטיין) ועמודת ה (פוליאסטר) לכן החלטנו לנסות להוריד אחת מהן ולראות מה ההשפעה על המודל אך גם כאן הייתה ירידה ברמת דיוק המודל"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56a0cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df=dataset.copy(deep=True)\n",
    "temp= dataset[\"elastane\"]\n",
    "tr_df.drop([\"elastane\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a6b27438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "======\n",
      "accuracy on train data 0.8378643956763839\n",
      "accuracy on test data 0.8078602620087336\n",
      "[[1724    0    0    0   35    5]\n",
      " [  18    0    0    0    6    2]\n",
      " [  21    0    0    1    7    1]\n",
      " [  47    0    0    3   50    4]\n",
      " [  79    0    0    4  113    5]\n",
      " [  97    0    0    1   57   10]]\n"
     ]
    }
   ],
   "source": [
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = tr_df\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"RandomForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42b743ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df[\"elastane\"]=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f235699",
   "metadata": {},
   "source": [
    "קיימת ירידה ברמת הדיוק של סט הבדיקה יחד עם סט המבחן לכן הורדנו גם את העמודה הזו"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d42e38",
   "metadata": {},
   "source": [
    "מהסתכלות בשלב הויזואליזציה, ראינו קורלציה גבוהה עד כמעט זהה בין עמודות\n",
    "\n",
    "(L, XL) ועמודות (XXL, XXXXL)\n",
    "\n",
    "לכן בחרנו להוריד את העמודות\n",
    "\n",
    "(xl, xxxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "480f214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "======\n",
      "accuracy on train data 0.8423408669068676\n",
      "accuracy on test data 0.8065502183406114\n",
      "[[1725    0    0    0   32    7]\n",
      " [  17    0    0    0    7    2]\n",
      " [  21    0    0    1    7    1]\n",
      " [  48    0    0    5   46    5]\n",
      " [  81    0    0    3  104   13]\n",
      " [  97    0    0    2   53   13]]\n"
     ]
    }
   ],
   "source": [
    "temp1= dataset[\"XL\"]\n",
    "temp2= dataset[\"XXXL\"]\n",
    "tr_df.drop([\"XL\",\"XXXL\"], inplace=True, axis=1)\n",
    "test_ratio, rand_state = 0.2, 42\n",
    "category_col_name = 'ratings'\n",
    "dataset = tr_df\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(dataset, category_col_name, test_ratio, rand_state)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"RandomForest\")\n",
    "print(\"======\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "print(\"accuracy on train data\",metrics.accuracy_score(y_true=y_train,y_pred=y_pred_train))\n",
    "print(\"accuracy on test data\",metrics.accuracy_score(y_true=y_test,y_pred=y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4831d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df[\"XL\"]=temp1\n",
    "tr_df[\"XXXL\"]=temp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee4592",
   "metadata": {},
   "source": [
    "ראינו שלאחר הורדת עמודות אלו לא ניראה שינוי בדיוק במודל, אך מהסתכלות בפיוזן מטריקס ראינו שיפור בזיהוי 5 כוכבים וירידה בזיהוי 4 כוכבים ולכן החלטנו להשאיר את הטבלה כמו שהיא."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55484a32",
   "metadata": {},
   "source": [
    "מסקנות:\n",
    "\n",
    "    הגענו למודל הכי טוב ברמת דיוק של כ- 81% ומכך אנו מסיקות כי ניתן לחזות את דירוג הפריט ברמת דיוק מסוימת.\n",
    "    \n",
    "    ניתן לראות מהכונפיוזין מטריקס שהרבה טעויות נעשו בסיווג פריטים אשר שיכים לקטגוריית האפס דבר אשר הגיוני כייון שפריטים רבים מדורגים 0 ישר בכניסתם לאתר ורק בהמשך עולים בדירוג.\n",
    "    \n",
    "    המודל נבדק ללא פריטים המדורגים 1 או 2 מה שגם יכול היה להשפיע על רמת הדיוק שלו.\n",
    "    \n",
    "    בנוסף ניתן לראות שחלק גדול מ4 הכוכבים מסווגים כ5 או 3 כוכבים וכך גם בדירוד 5 הכוכבים מה שמראה על בעייה ביכולת הבסיווג\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d13dbc",
   "metadata": {},
   "source": [
    "קישורים לאתרים בהם נעשה שימוש:\n",
    "https://medium.com/analytics-vidhya/random-forest-classifier-and-its-hyperparameters-8467bec755f6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
